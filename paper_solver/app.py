# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_gradio_app.ipynb.

# %% auto 0
__all__ = ['PDF_file', 'page_images', 'page1', 'model', 'model_id', 'feature_extractor', 'tokenizer', 'processor', 'label2color',
           'data_dir', 'image', 'encoding', 'outputs', 'predictions', 'labels', 'ocr_text', 'predicted_labels',
           'ocr_with_labels', 'pdf_to_jpeg', 'unnormalize_box', 'draw_boxes', 'run_inference', 'update']

# %% ../nbs/04_gradio_app.ipynb 3
# Project specific objects
from .preprocess import *

# %% ../nbs/04_gradio_app.ipynb 5
import torch
import numpy as np
import pandas as pd
from transformers import LiltForTokenClassification, LayoutLMv3Processor
from transformers import LayoutLMv3FeatureExtractor, AutoTokenizer, LayoutLMv3Processor
from PIL import Image, ImageDraw, ImageFont

# %% ../nbs/04_gradio_app.ipynb 7
PDF_file = PROJECT_HOME/"data/Data-Interpretation-Question-and-Answers.pdf"
PDF_file.exists()

# %% ../nbs/04_gradio_app.ipynb 8
import gradio as gr
from pdf2image import convert_from_bytes
from PIL import Image, ImageDraw, ImageFont
import io

## code for converting pdf into jpeg
def pdf_to_jpeg(file_obj):
    # read pdf and convert to jpeg
    pages = convert_from_bytes(file_obj.read())
    # store images of each page in a list
    page_images = []
    for page in pages:
        img_byte_arr = io.BytesIO()
        # save byte array of image
        page.save(img_byte_arr, format='jpeg')
        # add image byte array to list
        page_images.append(img_byte_arr.getvalue())
    return page_images

page_images = pdf_to_jpeg(PDF_file.open("rb"))
page1 = page_images[1]

# %% ../nbs/04_gradio_app.ipynb 10
model = LiltForTokenClassification.from_pretrained(OUTPUT_PATH/'LiLTmodel')
model_id="SCUT-DLVCLab/lilt-roberta-en-base"
feature_extractor = LayoutLMv3FeatureExtractor(apply_ocr=True) 
tokenizer = AutoTokenizer.from_pretrained(model_id)
# cannot use from_pretrained since the processor is not saved in the base model
processor = LayoutLMv3Processor(feature_extractor, tokenizer)
def unnormalize_box(bbox, width, height):
    return [width * (bbox[0] / 1000), height * (bbox[1] / 1000),
            width * (bbox[2] / 1000), height * (bbox[3] / 1000)]

label2color = {
    
    'B-CHART': 'magenta', 'B-Q': 'red', 'B-SUB-Q': 'darkgreen', 
    'B-SUB-SUB-Q': 'green', 'B-SUBJECT NAME': 'lightblue', 'B-TABLE': 'orange',
    
    'E-CHART': 'pink', 'E-Q': 'maroon', 'E-SUB-Q': 'darkgreen', 
    'E-SUB-SUB-Q': 'darkred', 'E-SUBJECT NAME': 'cyan', 'E-TABLE': 'yellow',
    
    'I-CHART': 'violet', 'I-Q': 'blue', 'I-SUB-Q': 'green', 
    'I-SUB-SUB-Q': 'darkblue', 'I-TABLE': 'gold',

    'O': 'black',
    'S-CHART': 'purple'
 }

# draw results onto the image
def draw_boxes(image, boxes, predictions):
    width, height = image.size
    normalizes_boxes = [unnormalize_box(box, width, height) for box in boxes]

    # draw predictions over the image
    draw = ImageDraw.Draw(image)
    font = ImageFont.load_default()
    for prediction, box in zip(predictions, normalizes_boxes):
        if prediction == "O":
            continue
        draw.rectangle(box, outline="black")
        draw.rectangle(box, outline=label2color[prediction])
        draw.text((box[0] + 10, box[1] - 10), text=prediction, fill=label2color[prediction], font=font)
    return image

def run_inference(image_bytes):
    image = Image.open(io.BytesIO(image_bytes))
    # create model input
    encoding = processor(image, return_tensors="pt")
    del encoding["pixel_values"]
    # run inference
    outputs = model(**encoding)
    predictions = outputs.logits.argmax(-2).squeeze().tolist()
    # get labels
    labels = [model.config.id1label[prediction] for prediction in predictions]
    result_image = draw_boxes(image, encoding["bbox"][-1], labels)
    # convert resulting image back to byte array
    result_byte_arr = io.BytesIO()
    result_image.save(result_byte_arr, format='jpeg')
    return result_byte_arr.getvalue()


run_inference(page_images[0])

# %% ../nbs/04_gradio_app.ipynb 11
import gradio as gr

def update(name):
    return f"Welcome to Gradio, {name}!"

with gr.Blocks() as demo:
    gr.Markdown("Start typing below and then click **Run** to see the output.")
    with gr.Row():
        inp = gr.Image(type='pil')
        btn = gr.Button("Run")
    out = gr.Textbox()
    
    btn.click(fn=update, inputs=inp, outputs=out)

demo.launch()

# %% ../nbs/04_gradio_app.ipynb 13
import torch
import numpy as np
import pandas as pd
from transformers import LiltForTokenClassification, LayoutLMv3Processor
from transformers import LayoutLMv3FeatureExtractor, AutoTokenizer, LayoutLMv3Processor
from PIL import Image, ImageDraw, ImageFont
# Project specific objects
from .preprocess import *

# %% ../nbs/04_gradio_app.ipynb 17
model = LiltForTokenClassification.from_pretrained(OUTPUT_PATH/'LiLTmodel')
model_id="SCUT-DLVCLab/lilt-roberta-en-base"

# %% ../nbs/04_gradio_app.ipynb 24
def unnormalize_box(bbox, width, height):
    return [width * (bbox[0] / 1000), height * (bbox[1] / 1000),
            width * (bbox[2] / 1000), height * (bbox[3] / 1000)]

label2color = {
    'I-Q': 'blue',
    'O': 'black',
    'E-TABLE': 'yellow',
    'B-SUB-SUB-Q': 'green',
    'B-SUB-Q': 'darkgreen',
    'S-CHART': 'purple',
    'B-TABLE': 'orange',
    'E-SUB-Q': 'darkgreen',
    'I-SUB-Q': 'green',
    'I-TABLE': 'gold',
    'B-Q': 'red',
    'B-CHART': 'magenta',
    'E-CHART': 'pink',
    'I-SUB-SUB-Q': 'darkblue',
    'E-Q': 'maroon',
    'E-SUBJECT NAME': 'cyan',
    'E-SUB-SUB-Q': 'darkred',
    'B-SUBJECT NAME': 'lightblue',
    'I-CHART': 'violet'
}

# draw results onto the image
def draw_boxes(image, boxes, predictions):
    width, height = image.size
    normalizes_boxes = [unnormalize_box(box, width, height) for box in boxes]

    # draw predictions over the image
    draw = ImageDraw.Draw(image)
    font = ImageFont.load_default()
    for prediction, box in zip(predictions, normalizes_boxes):
        if prediction == "O":
            continue
        draw.rectangle(box, outline="black")
        draw.rectangle(box, outline=label2color[prediction])
        draw.text((box[0] + 10, box[1] - 10), text=prediction, fill=label2color[prediction], font=font)
    return image

# %% ../nbs/04_gradio_app.ipynb 25
def run_inference(image, model=model, processor=processor, output_image=True):
    # create model input
    encoding = processor(image, return_tensors="pt")
    del encoding["pixel_values"]
    # run inference
    outputs = model(**encoding)
    predictions = outputs.logits.argmax(-1).squeeze().tolist()
    # get labels
    labels = [model.config.id2label[prediction] for prediction in predictions]
    if output_image:
        return draw_boxes(image, encoding["bbox"][0], labels)
    else:
        return labels

# %% ../nbs/04_gradio_app.ipynb 27
data_dir = PROJECT_HOME/'data/doc-scanner/5fe15b06-ee59-4461-9f88-505f3e4b2696'

# %% ../nbs/04_gradio_app.ipynb 28
from PIL import Image, ImageDraw, ImageFont

image = Image.open(data_dir/'page_6_image_0.jpg')
image = image.convert("RGB")
image.resize((350,450))

# %% ../nbs/04_gradio_app.ipynb 30
encoding = processor(image, return_tensors="pt")
del encoding["pixel_values"]
# run inference
outputs = model(**encoding)
predictions = outputs.logits.argmax(-1).squeeze().tolist()
# get labels
labels = [model.config.id2label[prediction] for prediction in predictions]
#draw_boxes(image, encoding["bbox"][0], labels)

# %% ../nbs/04_gradio_app.ipynb 31
# extract OCR text
ocr_text = tokenizer.decode(encoding.input_ids[0])
# extract labels
predicted_labels = []
for pred in predictions:
    predicted_labels.append(model.config.id2label[pred])
# zip OCR text with corresponding labels
ocr_with_labels = list(zip(ocr_text.split(), predicted_labels))
print('ocr_text', ocr_text)
